# 每周神经辐射场 [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
# 大部分为机器翻译，少数论文手动翻译，有翻译错误可以PR修复。

## 2022 年 7 月 31 日 - 8 月 6 日
- [NFOMP：具有非完整约束的差动驱动机器人最优运动规划器的神经场，IEEE 机器人和自动化快报](https://ieeexplore.ieee.org/abstract/document/9851532/) | [代码]
    > 摘要：最优运动规划是移动机器人中最关键的问题之一。一方面，经典的基于采样的方法为这个问题提出了渐近最优的解决方案。然而，这些规划器无法在合理的计算时间内实现平滑和短的轨迹。另一方面，基于优化的方法能够在各种场景中生成平滑而平坦的轨迹，包括密集的人群。然而，现代基于优化的方法使用预先计算的有符号距离函数进行碰撞损失估计，它限制了这些方法在一般配置空间中的应用，包括具有非完整约束的差分驱动非圆形机器人。此外，基于优化的方法缺乏准确处理 U 形或薄障碍物的能力。我们建议从两个方面改进优化方法。首先，我们开发了一个障碍物神经场模型来估计碰撞损失；将此模型与轨迹优化一起训练可以持续改善碰撞损失，同时实现更可行和更平滑的轨迹。其次，我们通过将拉格朗日乘数添加到轨迹损失函数中来强制轨迹考虑非完整约束。我们应用我们的方法解决了具有非完整约束的差动驱动机器人的最优运动规划问题，对我们的解决方案进行了基准测试，并证明了新的规划器生成了非常适合机器人跟随的平滑、短而平坦的轨迹，并且优于最先进的方法在归一化曲率上提高了 25%，在 MovingAI 环境中的尖点数量上提高了 75%。

- [NeSF: 用于 3D 场景的可概括语义分割的神经语义场](https://research.google/pubs/pub51563/) | [代码]
    > 我们提出了 NeSF，一种从预训练的密度场和稀疏的 2D 语义监督产生 3D 语义场的方法。我们的方法通过利用将 3D 信息存储在神经域中的神经表示来避开传统的场景表示。尽管仅由 2D 信号监督，我们的方法能够从新颖的相机姿势生成 3D 一致的语义图，并且可以在任意 3D 点进行查询。值得注意的是，NeSF 与任何产生密度场的方法兼容，并且随着预训练密度场质量的提高，其准确性也会提高。我们的实证分析证明了在令人信服的合成场景上与竞争性 2D 和 3D 语义分割基线相当的质量，同时还提供了现有方法无法提供的功能。

- [PRIF: Primary Ray-based Implicit Function](https://research.google/pubs/pub51556/) | [代码]
    > 我们引入了一种新的隐式形状表示，称为基于初级光线的隐式函数 (PRIF)。与大多数基于符号距离函数 (SDF) 处理空间位置的现有方法相比，我们的表示在定向射线上运行。具体来说，PRIF 被制定为直接生成给定输入射线的表面命中点，而无需昂贵的球体跟踪操作，从而实现高效的形状提取和可微渲染。我们证明了经过训练以编码 PRIF 的神经网络在各种任务中取得了成功，包括单一形状表示、类别形状生成、稀疏或嘈杂观察的形状补全、相机姿态估计的逆渲染以及颜色的神经渲染。

- [Transformers as Meta-Learners for Implicit Neural Representations, ECCV2022](https://arxiv.org/abs/2208.02801) | [代码](https://yinboc.github.io/trans-inr/)
    > 近年来，隐式神经表示 (INR) 已经出现并显示出其优于离散表示的优势。然而，将 INR 拟合到给定的观测值通常需要从头开始使用梯度下降进行优化，这是低效的，并且不能很好地泛化稀疏的观测值。为了解决这个问题，大多数先前的工作都训练了一个超网络，该超网络生成单个向量来调制 INR 权重，其中单个向量成为限制输出 INR 重建精度的信息瓶颈。最近的工作表明，通过基于梯度的元学习，可以在没有单向量瓶颈的情况下精确推断 INR 中的整个权重集。受基于梯度的元学习的广义公式的启发，我们提出了一个公式，该公式使用 Transformer 作为 INR 的超网络，它可以使用专门作为集合到集合映射的 Transformer 直接构建整个 INR 权重集。我们展示了我们的方法在不同任务和领域中构建 INR 的有效性，包括 2D 图像回归和 3D 对象的视图合成。我们的工作在 Transformer 超网络和基于梯度的元学习算法之间建立了联系，我们为理解生成的 INR 提供了进一步的分析。

- [全息显示3D相位全息图的端到端学习](https://www.nature.com/articles/s41377-022-00894-6) | [代码]
    > 计算机生成的全息术 (CGH) 提供相干波前的体积控制，是体积 3D 显示器、光刻、神经光刺激和光/声捕获等应用的基础。最近，基于深度学习的方法作为 CGH 合成的有前途的计算范式出现，克服了传统基于模拟/优化的方法中的质量-运行时权衡。然而，预测全息图的质量本质上受数据集质量的限制。在这里，我们介绍了一个新的全息图数据集 MIT-CGH-4K-V2，它使用分层深度图像作为数据高效的体积 3D 输入和用于直接合成高质量 3D 相位的两阶段监督+无监督训练协议-只有全息图。所提出的系统还可以校正视觉像差，从而允许为最终用户定制。我们通过实验展示了逼真的 3D 全息投影并讨论了相关的空间光调制器校准程序。我们的方法在消费级 GPU 上实时运行，在 iPhone 13 Pro 上以 5 FPS 运行，有望显着提高上述应用程序的性能。

- [VolTeMorph：体积表示的实时、可控和可泛化动画](https://arxiv.org/pdf/2208.00949) | [代码]
    > 最近，用于场景重建和新颖视图合成的体积表示越来越受欢迎，这使人们重新关注在高可见度下对体积内容进行动画处理质量和实时性。虽然基于学习函数的隐式变形方法可以产生令人印象深刻的结果，但它们对于艺术家和内容创作者来说是“黑匣子”，它们需要大量的训练数据才能进行有意义的概括，而且它们不会在训练数据之外产生现实的外推。在这项工作中，我们通过引入一种实时、易于使用现成软件进行编辑并且可以令人信服地推断的体积变形方法来解决这些问题。为了展示我们方法的多功能性，我们将其应用于两个场景：基于物理的对象变形和远程呈现，其中化身使用混合形状进行控制。我们还进行了彻底的实验，表明我们的方法优于结合隐式变形的体积方法和基于网格变形的方法。

- [基于神经辐射场和运动图的可控自由视点视频重建，IEEE Transactions on Visualization and Computer Graphics](https://ieeexplore.ieee.org/abstract/document/9845414) | [代码]
    > 在本文中，我们提出了一种基于运动图和神经辐射场（NeRF）的可控高质量自由视点视频生成方法。与现有的姿势驱动 NeRF 或时间/结构条件的 NeRF 工作不同，我们建议首先构建捕获序列的有向运动图。这种序列-运动-参数化策略不仅能够灵活地控制自由视点视频渲染的姿态，而且避免了相似姿态的冗余计算，从而提高了整体重建效率。此外，为了支持身体形状控制而不损失逼真的自由视点渲染性能，我们通过结合显式表面变形和隐式神经场景表示来改进 vanilla NeRF。具体来说，我们为运动图上的每个有效帧训练一个局部表面引导的 NeRF，并且体积渲染仅在真实表面周围的局部空间中执行，从而实现了合理的形状控制能力。据我们所知，我们的方法是第一个同时支持逼真的自由视点视频重建和基于运动图的用户引导运动遍历的方法。结果和比较进一步证明了所提出方法的有效性。

- [基于神经描述符字段的鲁棒变化检测，IROS2022](https://ieeexplore.ieee.org/abstract/document/9845414) | [代码](https://yilundu.github.io/ndf_change)
    > 在本文中，我们提出了一种基于运动图和神经辐射场（NeRF）的可控高质量自由视点视频生成方法。与现有的姿势驱动 NeRF 或时间/结构条件的 NeRF 工作不同，我们建议首先构建捕获序列的有向运动图。这种序列-运动-参数化策略不仅能够灵活地控制自由视点视频渲染的姿态，而且避免了相似姿态的冗余计算，从而提高了整体重建效率。此外，为了支持身体形状控制而不损失逼真的自由视点渲染性能，我们通过结合显式表面变形和隐式神经场景表示来改进 vanilla NeRF。具体来说，我们为运动图上的每个有效帧训练一个局部表面引导的 NeRF，并且体积渲染仅在真实表面周围的局部空间中执行，从而实现了合理的形状控制能力。据我们所知，我们的方法是第一个同时支持逼真的自由视点视频重建和基于运动图的用户引导运动遍历的方法。结果和比较进一步证明了所提出方法的有效性。

## 旧论文：
参考 [awesome-NeRF 代码仓库](https://github.com/yenchenlin/awesome-NeRF)。